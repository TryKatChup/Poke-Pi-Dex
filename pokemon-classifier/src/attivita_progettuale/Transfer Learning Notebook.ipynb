{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OP classifier for first 151 pokémon using transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use Pytorch and transfer learning with pretrained models (ResNet158, MobileNetV2 and MobileNetV3 large). Then, we'll compare all the results and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pip --upgrade\n",
    "!pip3 install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "\n",
    "We will use torchvision and torch.utils.data packages for loading the\n",
    "data.\n",
    "\n",
    "We have to train a model to classify Pokémon. There are 151 classes, with an average number of x images per class.\n",
    "This is a small dataset (if we compare with most popular datasets).\n",
    "We'll use transfer learning for this task.\n",
    "\n",
    "### 1.1 Dataset split\n",
    "\n",
    "The dataset must be already splitted into\n",
    "- **Train set (`train` folder)**: set of samples used during the learning process and is used to fit the parameters (e.g., weights).\n",
    "- **Validation set (`val` folder)**: set of samples used to tune the hyperparameters (i.e. the architecture) of the classifier. It should follow the same probability distribution as the training data set. \n",
    "- **Test set (`test` folder)**: set of samples used to see the performance of the classifier. It should follow the same probability distribution as the training data set. \n",
    "\n",
    "### 1.2 Data Augmentation\n",
    "\n",
    "Data augmentation is important to:\n",
    "\n",
    "- prevent overfitting;\n",
    "- have more samples; \n",
    "- prevent a neural network from learning irrelevant patterns, essentially boosting overall performance.\n",
    "\n",
    "The following transformation are applied to train set.\n",
    "\n",
    "- random resized crop;\n",
    "- random horizontal flip;\n",
    "- random perspective.\n",
    "\n",
    "Finally, `torchvision.transforms.Normalize()` subtracts the channel mean and divides by the channel standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomPerspective(distortion_scale=0.6, p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        # transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataloaders for train, val and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/tf/notebooks/Downloads/test-ml-net/pokemon-pytorch-nuovo/PokemonData/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val','test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val','test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if GPU or CPU is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if GPU is enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a few images in a grid to see some samples with data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data and show them as [image - pokémon name].\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training the model\n",
    "\n",
    "Now, let's write a general function to train a model. Here, we will\n",
    "illustrate:\n",
    "\n",
    "-  Scheduling the learning rate\n",
    "-  Saving the best model of all time\n",
    "\n",
    "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
    "``torch.optim.lr_scheduler``.\n",
    "\n",
    "### 2.1 Stochastic Gradient Descent\n",
    "\n",
    "Stochastic gradient descent (SGD) is an optimization algorithm that estimates the error gradient for the current state of the model using examples from the training dataset, then updates the weights of the model using the back-propagation of errors algorithm, referred to as simply backpropagation.\n",
    "\n",
    "### 2.2 Learning rate and the importance of scheduling the learning rate.\n",
    "\n",
    "The amount that the weights are updated during training is referred to as the step size or the _learning rate._\n",
    "\n",
    "The learning rate controls how quickly the model is adapted to the problem. Smaller learning rates require more training epochs given the smaller changes made to the weights each update, whereas larger learning rates result in rapid changes and require fewer training epochs\n",
    "\n",
    "A learning rate that is too large can cause the model to converge too quickly to a suboptimal solution, whereas a learning rate that is too small can cause the process to get stuck.\n",
    "\n",
    "\n",
    "### 2.3 Learning rate scheduler\n",
    "\n",
    "A Learning rate scheduler is a predefined framework that adjusts the learning rate between epochs or iterations as the training progresses. We'll use _learning rate decay_: we select an initial learning rate, then gradually reduce it in accordance with a scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            writer.add_scalar(\"epoch_loss\", epoch_loss, epoch)\n",
    "            writer.add_scalar(\"epoch_acc\", epoch_acc, epoch)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "                              \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    " \n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See all Pokémon names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finetuning the model\n",
    "\n",
    "Load a pretrained model and reset final fully connected layer (`nn.Linear`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet152(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "############## MobileNetV2 ##################\n",
    "#model_ft = models.mobilenet_v2(pretrained=True)\n",
    "#model_ft.classifier = nn.Linear(1280, 151)\n",
    "#############################################\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing the model predictions\n",
    "\n",
    "Generic function to display predictions for a few images from test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Obtain test loss and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_losses=[]\n",
    "eval_accu=[]\n",
    "\n",
    "model_ft.eval()\n",
    "running_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in dataloaders['test']:\n",
    "        images, labels = data[0].to(device),data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model_ft(images)\n",
    "        loss= criterion(outputs,labels)\n",
    "        running_loss+=loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "   \n",
    "    test_loss=running_loss/len(dataloaders['test'])\n",
    "    accu=100.*correct/total\n",
    "\n",
    "    eval_losses.append(test_loss)\n",
    "    eval_accu.append(accu)\n",
    "\n",
    "    print('Test Loss: %.3f | Accuracy: %.3f'%(test_loss,accu)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), \"/tf/notebooks/Downloads/test-ml-net/pokemon-pytorch-nuovo/nuovomobilenetv3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new model (pls) and load all trained weights and bias on CPU. Fix, onnx export doesn't like GPUs as model source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls = models.mobilenet_v3_large(pretrained=False)\n",
    "#pls2 = pls.fc.in_features\n",
    "#pls.classifier = nn.Linear(1280, 151)\n",
    "pls.load_state_dict(torch.load(\"/tf/notebooks/Downloads/test-ml-net/pokemon-pytorch-nuovo/nuovomobilenetv3\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls.eval()\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "input_names = [ \"actual_input\" ]\n",
    "output_names = [ \"output\" ]\n",
    "torch.onnx.export(pls,\n",
    "                  dummy_input,\n",
    "                  \"/tf/notebooks/Downloads/test-ml-net/pokemon-pytorch-nuovo/nuovomobilenetv3.onnx\",\n",
    "                  verbose=False,\n",
    "                  input_names=input_names,\n",
    "                  output_names=output_names,\n",
    "                  export_params=True,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install onnx-tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to tensorflow model (`pb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!onnx-tf convert -i /tf/notebooks/Downloads/test-ml-net/pokemon-pytorch-nuovo/nuovomobilenetv3.onnx -o /tf/notebooks/Downloads/test-ml-net/pokemon-pytorch-nuovo/nuovomobilenetv3.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Convert model to `.tflite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!tflite_convert --saved_model_dir=/tf/notebooks/Downloads/test-ml-net/pokemon-pytorch-nuovo/nuovomobilenetv3.pb --output_file=/tf/notebooks/Downloads/test-ml-net/pokemon-pytorch-nuovo/nuovomobilenetv3.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "device = torch.device('cpu')\n",
    "#mobilenet = models.mobilenet_v2(pretrained=False)\n",
    "#mobilenet.classifier = nn.Linear(1280, 151)\n",
    "#model = torch.load('./nuovomobilenetv2', map_location=device)\n",
    "#mobilenet.load_state_dict(model)\n",
    "#mobilenet.eval()\n",
    "model_ft = models.resnet152(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 151)\n",
    "model = torch.load('./nuovoresnet152', map_location=device)\n",
    "model_ft.load_state_dict(model)\n",
    "model_ft.eval()\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = './13.jpg'\n",
    "pic = Image.open(pic)\n",
    "image_tensor = test_transforms(pic).float()\n",
    "image_tensor = image_tensor.unsqueeze_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_ft(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7383e-03, 8.2524e-04, 6.5247e-05, 3.5071e-04, 5.9408e-05, 6.6976e-06,\n",
      "         1.4547e-04, 3.2106e-04, 2.8036e-04, 7.4395e-06, 2.9445e-05, 3.3467e-05,\n",
      "         2.2372e-04, 6.6766e-02, 1.2478e-01, 9.8978e-02, 1.7174e-03, 2.3714e-04,\n",
      "         3.9810e-05, 1.9131e-02, 4.8765e-04, 1.1620e-04, 7.3980e-05, 8.7539e-05,\n",
      "         7.3875e-05, 1.7003e-04, 2.5404e-02, 3.0819e-05, 3.4128e-04, 1.2524e-04,\n",
      "         8.3029e-04, 7.1679e-05, 2.6630e-05, 3.0326e-05, 3.7306e-04, 2.8351e-04,\n",
      "         8.6665e-04, 3.2153e-04, 2.3990e-04, 2.4375e-05, 7.4555e-05, 6.5681e-04,\n",
      "         7.5601e-05, 1.8700e-05, 8.1081e-04, 3.6523e-04, 4.3538e-04, 2.7829e-05,\n",
      "         2.6076e-04, 3.6693e-04, 3.1814e-04, 1.1249e-04, 1.2006e-03, 7.2104e-03,\n",
      "         3.0793e-05, 6.2694e-04, 1.2077e-05, 3.3869e-04, 1.4274e-05, 2.9443e-05,\n",
      "         1.7436e-05, 2.4287e-03, 4.6200e-04, 6.1250e-05, 2.0974e-02, 2.4703e-03,\n",
      "         1.2571e-05, 2.2984e-02, 1.1872e-03, 2.8446e-03, 1.8476e-04, 4.6945e-05,\n",
      "         5.1476e-03, 3.4747e-04, 8.0557e-04, 7.5826e-05, 2.3252e-05, 2.3391e-03,\n",
      "         9.8793e-02, 3.3116e-03, 2.7832e-04, 3.0356e-01, 1.1225e-01, 2.9943e-04,\n",
      "         1.7195e-03, 6.5009e-05, 3.1202e-03, 1.8356e-04, 5.0852e-05, 1.8251e-04,\n",
      "         4.4953e-05, 1.8598e-04, 2.8582e-04, 1.7595e-06, 2.5821e-05, 4.7705e-05,\n",
      "         3.2897e-04, 3.1683e-04, 5.8273e-04, 1.1335e-02, 5.2327e-04, 2.5016e-03,\n",
      "         1.3189e-04, 6.4367e-05, 1.2847e-03, 1.9092e-06, 1.4506e-05, 6.2049e-05,\n",
      "         6.8399e-03, 8.3139e-05, 1.2382e-04, 2.9386e-04, 5.6574e-04, 4.0213e-03,\n",
      "         1.3293e-03, 1.7021e-03, 4.7762e-04, 2.2170e-04, 1.6222e-03, 3.6466e-03,\n",
      "         3.5369e-04, 1.3243e-05, 4.6266e-05, 1.0029e-03, 6.5303e-06, 1.5038e-03,\n",
      "         1.0055e-03, 8.2675e-04, 4.9428e-04, 3.0247e-04, 1.1646e-05, 1.4724e-04,\n",
      "         7.3840e-06, 8.6967e-04, 2.5739e-04, 3.9819e-05, 4.0674e-05, 6.6423e-05,\n",
      "         5.2346e-06, 2.6507e-05, 8.2714e-05, 2.0494e-05, 1.6949e-04, 7.6609e-03,\n",
      "         4.8657e-04, 2.3473e-04, 3.7940e-05, 1.3569e-05, 5.6997e-04, 3.1343e-05,\n",
      "         6.1416e-05]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sm = nn.Softmax(dim = 1)\n",
    "probs = sm(output)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = np.load('./best_classes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mew' 'Charmander' 'Mewtwo' 'Charmeleon' 'Marowak'] [81 14 82 15 78]\n"
     ]
    }
   ],
   "source": [
    "(top_k_scores, top_k_idx) = torch.topk(probs, 5)\n",
    "top_k_scores = top_k_scores.detach().numpy()\n",
    "top_k_scores = np.squeeze(top_k_scores, axis=0)\n",
    "top_k_idx = np.squeeze(top_k_idx.numpy(), axis=0)\n",
    "top_k_labels = label_encoder.inverse_transform(top_k_idx)\n",
    "\n",
    "print(top_k_labels, top_k_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6879, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.max(probs)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}