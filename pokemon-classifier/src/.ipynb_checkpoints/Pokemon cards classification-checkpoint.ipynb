{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1b117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pydot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pc  # custom module\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Check CUDA support\n",
    "if len(tf.config.list_physical_devices(\"GPU\")) > 0:\n",
    "    print(\"CUDA enabled.\")\n",
    "else:\n",
    "    print(\"CUDA not enabled.\")\n",
    "\n",
    "# Path to dataset\n",
    "data_folder = \"/app/data/PokemonData\"\n",
    "# Training parameters\n",
    "EP = 100\n",
    "BS = 16\n",
    "# Image resolution\n",
    "RES = (224, 224)\n",
    "# Random seed\n",
    "SEED = 42\n",
    "\n",
    "# Enable automatic mixed precision (not compatible with my GPU GeForce GTX 1060 6GB)\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab145474",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /app/data/PokemonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pc.create_dataset(\n",
    "    data_folder,\n",
    "    epochs=EP,\n",
    "    batch_size=BS,\n",
    "    res=RES,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6284247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = data_dict[\"train_dataset\"]\n",
    "val_dataset = data_dict[\"val_dataset\"]\n",
    "test_dataset = data_dict[\"test_dataset\"]\n",
    "train_len = data_dict[\"train_len\"]\n",
    "val_len = data_dict[\"val_len\"]\n",
    "test_len = data_dict[\"test_len\"]\n",
    "label_encoder = data_dict[\"label_encoder\"]\n",
    "# print(list(label_encoder.classes_))\n",
    "# np.save('classes.npy', label_encoder.classes_)\n",
    "print(f\"Number of training samples: {train_len}\")\n",
    "print(f\"Number of validation samples: {val_len}\")\n",
    "print(f\"Number of test samples: {test_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Iterate over batches\n",
    "for (image_batch, label_batch) in train_dataset:\n",
    "    # Iterate over elements in batch\n",
    "    for i, (image, label) in enumerate(zip(image_batch[:8], label_batch[:8])):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.title(label_encoder.inverse_transform([label]))\n",
    "        plt.imshow((255 * image.numpy()).astype(np.uint8))\n",
    "    break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = {\n",
    "    label_encoder.inverse_transform([i])[0]: 0\n",
    "    for i in range(151)\n",
    "}\n",
    "train_it = iter(train_dataset)\n",
    "for i in range(train_len // BS):\n",
    "    (_, label_batch) = next(train_it)\n",
    "    for label in label_batch:\n",
    "        label_name = label_encoder.inverse_transform([label])[0]\n",
    "        train_labels[label_name] += 1\n",
    "print(\"Training: done\")\n",
    "\n",
    "val_labels = {\n",
    "    label_encoder.inverse_transform([i])[0]: 0\n",
    "    for i in range(151)\n",
    "}\n",
    "val_it = iter(val_dataset)\n",
    "for i in range(val_len // BS):\n",
    "    (_, label_batch) = next(val_it)\n",
    "    for label in label_batch:\n",
    "        label_name = label_encoder.inverse_transform([label])[0]\n",
    "        val_labels[label_name] += 1\n",
    "print(\"Validation: done\")\n",
    "        \n",
    "#val_labels = [0 for _ in range(151)]\n",
    "#val_it = iter(val_dataset)\n",
    "#for i in range(val_len // BS):\n",
    "#    (_, label_batch) = next(val_it)\n",
    "#    for label in label_batch:\n",
    "#        val_labels[label.numpy()] +=1\n",
    "#print(\"Validation: done\")\n",
    "\n",
    "test_labels = {\n",
    "    label_encoder.inverse_transform([i])[0]: 0\n",
    "    for i in range(151)\n",
    "}\n",
    "#test_labels = [0 for _ in range(151)]\n",
    "test_it = iter(test_dataset)\n",
    "for i, (_, label) in enumerate(test_it):\n",
    "    label_name = label_encoder.inverse_transform([label])[0]\n",
    "    test_labels[label_name] += 1\n",
    "    #test_labels[label.numpy()[0]]+=1\n",
    "print(\"Test: done\")\n",
    "\n",
    "plt.figure(figsize=(10, 40))\n",
    "\n",
    "plt.title(\"Training classes\")\n",
    "plt.barh(list(train_labels.keys()), train_labels.values())\n",
    "\n",
    "plt.figure(figsize=(10, 40))\n",
    "plt.title(\"Validation classes\")\n",
    "plt.barh(list(val_labels.keys()), val_labels.values())\n",
    "\n",
    "plt.figure(figsize=(10, 40))\n",
    "plt.title(\"Test classes\")\n",
    "plt.barh(list(test_labels.keys()), test_labels.values())\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.subplot(3, 1, 1)\n",
    "# plt.plot(train_labels)\n",
    "# plt.title(\"Training classes\")\n",
    "# plt.subplot(3, 1, 2)\n",
    "# plt.plot(val_labels)\n",
    "# plt.title(\"Validation classes\")\n",
    "# plt.subplot(3, 1, 3)\n",
    "# plt.plot(test_labels)\n",
    "# plt.title(\"Test classes\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9368155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pc.create_model(n_conv=5, use_bn=True, res=RES)\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6647137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EP,\n",
    "    callbacks=[callback],\n",
    "    steps_per_epoch=train_len // BS,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=val_len // BS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a6fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model (tensorflow standard format)\n",
    "model.save(\"new_model_no_bright_contrast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = model.evaluate(\n",
    "    test_dataset,\n",
    "    steps=test_len,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))  # set graph dimension\n",
    "\n",
    "# 1. First graph\n",
    "\n",
    "plt.subplot(1, 2, 1)  # creates 1 subplot out of 2\n",
    "\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.plot(history.history[\"loss\"], label=\"Training loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "\n",
    "# 2. Second Graph\n",
    "\n",
    "plt.subplot(1, 2, 2)  # creates 1 subplot out of 2\n",
    "\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = load_img(\"./evee_1.jpg\", target_size=(224, 224))\n",
    "plt.imshow(img)\n",
    "img = img_to_array(img, dtype=np.float32)\n",
    "img /= 255\n",
    "img = np.expand_dims(img, axis=0)\n",
    "score = pc.top_k_predictions(model, img, label_encoder)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "model = tf.keras.models.load_model('./model_best_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a7ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model_name.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a59c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import os\n",
    "\n",
    "#model = tf.keras.models.load_model(\"./model_best_100\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.SIZE]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_quant_model = converter.convert()#save converted quantization model to tflite format\n",
    "open(\"qa_model_no_soft.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d4bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"./model_best_100\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()#save converted quantization model to tflite format\n",
    "open(\"qa_model_no_soft_8bit.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba907206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eaa7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "# import cv2\n",
    "\n",
    "TFLITE_MODEL=\"./qa_model_best100_8bit.tflite\"\n",
    "interpreter = tf.lite.Interpreter(TFLITE_MODEL)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Load image\n",
    "img = load_img(\"./evee_1.jpg\", target_size=(224, 224))\n",
    "plt.imshow(img)\n",
    "img = img_to_array(img, dtype=np.float32)\n",
    "img /= 255\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "input_tensor = np.array(img, dtype=np.float32)\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b5ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pc\n",
    "\n",
    "(top_k_scores, top_k_idx) = tf.math.top_k(output_data, 5)\n",
    "top_k_scores = np.squeeze(top_k_scores.numpy(), axis=0)\n",
    "top_k_idx = np.squeeze(top_k_idx.numpy(), axis=0)\n",
    "top_k_labels = label_encoder.inverse_transform(top_k_idx)\n",
    "print (top_k_labels, top_k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a9c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
