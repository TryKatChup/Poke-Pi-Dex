{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078474f5",
   "metadata": {},
   "source": [
    "Import all necessary modules and check GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4671381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pydot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pc  # custom module\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Check CUDA support\n",
    "if len(tf.config.list_physical_devices(\"GPU\")) > 0:\n",
    "    print(\"CUDA enabled.\")\n",
    "else:\n",
    "    print(\"CUDA not enabled.\")\n",
    "\n",
    "# Enable automatic mixed precision (not compatible with my GPU GeForce GTX 1060 6GB)\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed431067",
   "metadata": {},
   "source": [
    "Set folder with dataset, number of epochs, batch size, resolution and seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "data_folder = \"/app/data/PokemonData\"\n",
    "# Training parameters\n",
    "EP = 100\n",
    "BS = 16\n",
    "# Image resolution\n",
    "RES = (224, 224)\n",
    "# Random seed\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d2d73",
   "metadata": {},
   "source": [
    "Create dataset with specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pc.create_dataset(\n",
    "    data_folder,\n",
    "    epochs=EP,\n",
    "    batch_size=BS,\n",
    "    res=RES,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd9693",
   "metadata": {},
   "source": [
    "Split dataset into train, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4dad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_dict[\"train_dataset\"]\n",
    "val_dataset = data_dict[\"val_dataset\"]\n",
    "test_dataset = data_dict[\"test_dataset\"]\n",
    "label_encoder = data_dict[\"label_encoder\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb07d8",
   "metadata": {},
   "source": [
    "Get length of train, validation and test set. Print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = data_dict[\"train_len\"]\n",
    "val_len = data_dict[\"val_len\"]\n",
    "test_len = data_dict[\"test_len\"]\n",
    "# print(list(label_encoder.classes_))\n",
    "# np.save('classes.npy', label_encoder.classes_)\n",
    "print(f\"Number of training samples: {train_len}\")\n",
    "print(f\"Number of validation samples: {val_len}\")\n",
    "print(f\"Number of test samples: {test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a232f",
   "metadata": {},
   "source": [
    "Associate image to label encoder. Show 8 samples from train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c94da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Iterate over batches\n",
    "for (image_batch, label_batch) in train_dataset:\n",
    "    # Iterate over elements in batch\n",
    "    for i, (image, label) in enumerate(zip(image_batch[:8], label_batch[:8])):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.title(label_encoder.inverse_transform([label]))\n",
    "        plt.imshow((255 * image.numpy()).astype(np.uint8))\n",
    "    break\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa3f420",
   "metadata": {},
   "source": [
    "Get all train, validation, and test labels. Plot 3 graphs with the number of each Pok√©mon for train, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d804b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = {\n",
    "    label_encoder.inverse_transform([i])[0]: 0\n",
    "    for i in range(151)\n",
    "}\n",
    "train_it = iter(train_dataset)\n",
    "for i in range(train_len // BS):\n",
    "    (_, label_batch) = next(train_it)\n",
    "    for label in label_batch:\n",
    "        label_name = label_encoder.inverse_transform([label])[0]\n",
    "        train_labels[label_name] += 1\n",
    "print(\"Training: done\")\n",
    "\n",
    "val_labels = {\n",
    "    label_encoder.inverse_transform([i])[0]: 0\n",
    "    for i in range(151)\n",
    "}\n",
    "val_it = iter(val_dataset)\n",
    "for i in range(val_len // BS):\n",
    "    (_, label_batch) = next(val_it)\n",
    "    for label in label_batch:\n",
    "        label_name = label_encoder.inverse_transform([label])[0]\n",
    "        val_labels[label_name] += 1\n",
    "print(\"Validation: done\")\n",
    "        \n",
    "#val_labels = [0 for _ in range(151)]\n",
    "#val_it = iter(val_dataset)\n",
    "#for i in range(val_len // BS):\n",
    "#    (_, label_batch) = next(val_it)\n",
    "#    for label in label_batch:\n",
    "#        val_labels[label.numpy()] +=1\n",
    "#print(\"Validation: done\")\n",
    "\n",
    "test_labels = {\n",
    "    label_encoder.inverse_transform([i])[0]: 0\n",
    "    for i in range(151)\n",
    "}\n",
    "#test_labels = [0 for _ in range(151)]\n",
    "test_it = iter(test_dataset)\n",
    "for i, (_, label) in enumerate(test_it):\n",
    "    label_name = label_encoder.inverse_transform([label])[0]\n",
    "    test_labels[label_name] += 1\n",
    "    #test_labels[label.numpy()[0]]+=1\n",
    "print(\"Test: done\")\n",
    "\n",
    "plt.figure(figsize=(10, 40))\n",
    "\n",
    "plt.title(\"Training classes\")\n",
    "plt.barh(list(train_labels.keys()), train_labels.values())\n",
    "\n",
    "plt.figure(figsize=(10, 40))\n",
    "plt.title(\"Validation classes\")\n",
    "plt.barh(list(val_labels.keys()), val_labels.values())\n",
    "\n",
    "plt.figure(figsize=(10, 40))\n",
    "plt.title(\"Test classes\")\n",
    "plt.barh(list(test_labels.keys()), test_labels.values())\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.subplot(3, 1, 1)\n",
    "# plt.plot(train_labels)\n",
    "# plt.title(\"Training classes\")\n",
    "# plt.subplot(3, 1, 2)\n",
    "# plt.plot(val_labels)\n",
    "# plt.title(\"Validation classes\")\n",
    "# plt.subplot(3, 1, 3)\n",
    "# plt.plot(test_labels)\n",
    "# plt.title(\"Test classes\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfcc41",
   "metadata": {},
   "source": [
    "ResNet with some specs I'll modify later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae8669",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    include_top=False, weights='imagenet', pooling=\"avg\", input_shape=(224, 224, 3)\n",
    ")\n",
    "#base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6458ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=True)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(151)(x)\n",
    "outputs = tf.keras.layers.Softmax()(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e490655",
   "metadata": {},
   "source": [
    "Compile model with specified optimizer (and change learning rate and so on pls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ecc72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Da cambiare assolutamente questa parte\n",
    "#opt = tf.keras.optimizers.RMSprop(learning_rate=1e-4, momentum=0.9)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "#opt = tf.keras.optimizers.Adam()#learning_rate=0.01\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(), # from_logits=True: output is not normalized, softmax function will be automatically applied\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9dfc58",
   "metadata": {},
   "source": [
    "Fit model with `EarlyStopping` and `patience = 10`, and get the best model before the last worst 10 epochs. Monitor validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a596678",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EP,\n",
    "    callbacks=[callback],\n",
    "    steps_per_epoch=train_len // BS,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=val_len // BS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=True\n",
    "opt2 = tf.keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9, nesterov=True)\n",
    "model.compile(\n",
    "    optimizer=opt2,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(), # from_logits=True: output is not normalized, softmax function will be automatically applied\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EP,\n",
    "    callbacks=[callback],\n",
    "    steps_per_epoch=train_len // BS,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=val_len // BS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f36997",
   "metadata": {},
   "source": [
    "Save model (Tensorflow standard format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model (tensorflow standard format)\n",
    "model.save(\"new_model_no_bright_contrast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c18ef4",
   "metadata": {},
   "source": [
    "Test model with test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = model.evaluate(\n",
    "    test_dataset,\n",
    "    steps=test_len,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17febe9c",
   "metadata": {},
   "source": [
    "Plot train, validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceeb809",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))  # set graph dimension\n",
    "\n",
    "# 1. First graph\n",
    "\n",
    "plt.subplot(1, 2, 1)  # creates 1 subplot out of 2\n",
    "\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.plot(history.history[\"loss\"], label=\"Training loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "\n",
    "# 2. Second Graph\n",
    "\n",
    "plt.subplot(1, 2, 2)  # creates 1 subplot out of 2\n",
    "\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"#Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecef577f",
   "metadata": {},
   "source": [
    "Convert keras model to tflite model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model_name.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b00c19",
   "metadata": {},
   "source": [
    "Model quantization on tflite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"./model_best_100\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()#save converted quantization model to tflite format\n",
    "open(\"resnet_model_qa_8bit.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_tensor=tf.keras.Input(shape=(224, 224, 3)),\n",
    "    pooling='avg', classes=151\n",
    ")\n",
    "# model.trainable=False\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
